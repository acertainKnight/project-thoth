# Thoth Configuration Example
# Copy this file to .env and fill in your actual values.
# Sections are ordered logically for easier management.

# ----------------------------------------------------------------------------------
# --- 1. API Keys ---
# (Controls: src.thoth.utilities.config.APIKeys, env_prefix='API_')
# ----------------------------------------------------------------------------------
API_MISTRAL_KEY="your_mistral_api_key_here"
API_OPENROUTER_KEY="your_openrouter_api_key_here"
API_OPENAI_KEY=""
API_ANTHROPIC_KEY=""
API_OPENCITATIONS_KEY="your_opencitations_api_key_here"
API_GOOGLE_API_KEY=""
API_GOOGLE_SEARCH_ENGINE_ID=""
API_SEMANTICSCHOLAR_API_KEY=""

# ----------------------------------------------------------------------------------
# --- 2. Default Model Settings ---
# (Controls: src.thoth.utilities.config.ModelConfig, env_prefix='MODEL_')
# These are global defaults for any LLM model settings.
# They can be overridden by specific settings in LLMConfig and CitationLLMConfig.
# ----------------------------------------------------------------------------------
MODEL_TEMPERATURE="0.9"
MODEL_MAX_TOKENS="500000"
MODEL_TOP_P="1.0"
MODEL_FREQUENCY_PENALTY="0.0"
MODEL_PRESENCE_PENALTY="0.0"
MODEL_STREAMING="False"
MODEL_USE_RATE_LIMITER="True"

# ----------------------------------------------------------------------------------
# --- 3. General LLM Configuration ---
# (Controls: src.thoth.utilities.config.LLMConfig, env_prefix='LLM_')
# Configuration for the primary LLM used for content analysis, etc.
# ----------------------------------------------------------------------------------
LLM_MODEL="mistralai/Mixtral-8x7B-Instruct-v0.1"
LLM_MODEL_SETTINGS_TEMPERATURE="0.9"
LLM_MODEL_SETTINGS_MAX_TOKENS="500000"
LLM_MODEL_SETTINGS_TOP_P="1.0"
LLM_MODEL_SETTINGS_FREQUENCY_PENALTY="0.0"
LLM_MODEL_SETTINGS_PRESENCE_PENALTY="0.0"
LLM_MODEL_SETTINGS_STREAMING="False"
LLM_MODEL_SETTINGS_USE_RATE_LIMITER="True"
LLM_DOC_PROCESSING="auto"
LLM_MAX_OUTPUT_TOKENS="500000"
LLM_MAX_CONTEXT_LENGTH="8000"
LLM_CHUNK_SIZE="4000"
LLM_CHUNK_OVERLAP="200"
LLM_REFINE_THRESHOLD_MULTIPLIER="1.2"
LLM_MAP_REDUCE_THRESHOLD_MULTIPLIER="3.0"

# ----------------------------------------------------------------------------------
# --- 4. Citation LLM Configuration ---
# (Controls: src.thoth.utilities.config.CitationLLMConfig, env_prefix='CITATION_LLM_')
# Configuration for the LLM used specifically for citation-related tasks.
# ----------------------------------------------------------------------------------
CITATION_LLM_MODEL="openai/gpt-3.5-turbo"
CITATION_LLM_MODEL_SETTINGS_TEMPERATURE="0.9"
CITATION_LLM_MODEL_SETTINGS_MAX_TOKENS="10000"
CITATION_LLM_MODEL_SETTINGS_TOP_P="1.0"
CITATION_LLM_MODEL_SETTINGS_FREQUENCY_PENALTY="0.0"
CITATION_LLM_MODEL_SETTINGS_PRESENCE_PENALTY="0.0"
CITATION_LLM_MODEL_SETTINGS_STREAMING="False"
CITATION_LLM_MODEL_SETTINGS_USE_RATE_LIMITER="True"
CITATION_LLM_MAX_OUTPUT_TOKENS="10000"
CITATION_LLM_MAX_CONTEXT_LENGTH="4000"

# ----------------------------------------------------------------------------------
# --- 4.5. Tag Consolidator LLM Configuration ---
# (Controls: src.thoth.utilities.config.TagConsolidatorLLMConfig, env_prefix='TAG_LLM_')
# LLM for tag consolidation and suggestion tasks.
# ----------------------------------------------------------------------------------
TAG_LLM_CONSOLIDATE_MODEL="google/gemini-flash-1.5-8b"
TAG_LLM_SUGGEST_MODEL="google/gemini-flash-1.5-8b"
TAG_LLM_MAP_MODEL="mistralai/ministral-3b"
TAG_LLM_MODEL_SETTINGS_TEMPERATURE="0.9"
TAG_LLM_MODEL_SETTINGS_MAX_TOKENS="10000"
TAG_LLM_MODEL_SETTINGS_TOP_P="1.0"
TAG_LLM_MODEL_SETTINGS_FREQUENCY_PENALTY="0.0"
TAG_LLM_MODEL_SETTINGS_PRESENCE_PENALTY="0.0"
TAG_LLM_MODEL_SETTINGS_STREAMING="False"
TAG_LLM_MODEL_SETTINGS_USE_RATE_LIMITER="True"
TAG_LLM_MAX_OUTPUT_TOKENS="10000"
TAG_LLM_MAX_CONTEXT_LENGTH="8000"

# ----------------------------------------------------------------------------------
# --- 5. Citation Processing Configuration ---
# (Controls: src.thoth.utilities.config.CitationConfig, env_prefix='CITATION_')
# Non-LLM settings for citation handling.
# ----------------------------------------------------------------------------------
CITATION_LINK_FORMAT="uri"
CITATION_STYLE="IEEE"
CITATION_USE_OPENCITATIONS="True"
CITATION_USE_SCHOLARLY="True"
CITATION_USE_SEMANTICSCHOLAR="False"
CITATION_USE_ARXIV="False"
CITATION_CITATION_BATCH_SIZE="5"

# ----------------------------------------------------------------------------------
# --- 6. Endpoint Configuration ---
# (Controls: src.thoth.utilities.config.EndpointConfig, env_prefix='ENDPOINT_')
# Settings for the API server endpoint.
# ----------------------------------------------------------------------------------
ENDPOINT_HOST="0.0.0.0"
ENDPOINT_PORT="8000"
ENDPOINT_BASE_URL="http://localhost:8000"
ENDPOINT_AUTO_START="False"

# ----------------------------------------------------------------------------------
# --- 7. Monitor Configuration ---
# (Controls: src.thoth.utilities.config.MonitorConfig, env_prefix='MONITOR_')
# Settings for the file monitoring service.
# ----------------------------------------------------------------------------------
MONITOR_AUTO_START="False"
MONITOR_WATCH_INTERVAL="10"
MONITOR_BULK_PROCESS_SIZE="10"

# ----------------------------------------------------------------------------------
# --- 8. Logging Configuration ---
# (Controls: src.thoth.utilities.config.LoggingConfig, env_prefix='LOG_')
# ----------------------------------------------------------------------------------
LOG_LEVEL="INFO"
LOG_LOGFORMAT="{time} | {level} | {file}:{line} | {function} | {message}"
LOG_DATEFORMAT="YYYY-MM-DD HH:mm:ss"
LOG_FILENAME="logs/thoth.log"
LOG_FILEMODE="a"
LOG_FILE_LEVEL="INFO"

# ----------------------------------------------------------------------------------
# --- 9. Thoth Base Paths (Defaults from ThothConfig) ---
# These are typically not set in .env unless you need to override the defaults
# defined in src.thoth.utilities.config.ThothConfig.
# They are loaded directly by ThothConfig without a prefix.
# ----------------------------------------------------------------------------------
WORKSPACE_DIR="/app"
PDF_DIR="data/pdf"
MARKDOWN_DIR="data/markdown"
NOTES_DIR="data/notes"
PROMPTS_DIR="data/prompts"
TEMPLATES_DIR="data/templates"
OUTPUT_DIR="data/output"
KNOWLEDGE_BASE_DIR="data/knowledge"
GRAPH_STORAGE_PATH="data/graph/citations.graphml"
QUERIES_DIR="data/queries"
AGENT_STORAGE_DIR="data/agent"
# --- Discovery folders ---
DISCOVERY_SOURCES_DIR="data/discovery/sources"
DISCOVERY_RESULTS_DIR="data/discovery/results"
CHROME_EXTENSION_CONFIGS_DIR="data/discovery/chrome_configs"

# ----------------------------------------------------------------------------------
# --- 10. Research Agent LLM Configuration ---
# (Controls: src.thoth.utilities.config.ResearchAgentLLMConfig, env_prefix='RESEARCH_AGENT_LLM_')
# LLM for research agent conversational interface and query management.
# ----------------------------------------------------------------------------------
RESEARCH_AGENT_LLM_MODEL="anthropic/claude-3.5-sonnet:beta"
RESEARCH_AGENT_LLM_MODEL_SETTINGS_TEMPERATURE="0.9"
RESEARCH_AGENT_LLM_MODEL_SETTINGS_MAX_TOKENS="50000"
RESEARCH_AGENT_LLM_MODEL_SETTINGS_TOP_P="1.0"
RESEARCH_AGENT_LLM_MODEL_SETTINGS_FREQUENCY_PENALTY="0.0"
RESEARCH_AGENT_LLM_MODEL_SETTINGS_PRESENCE_PENALTY="0.0"
RESEARCH_AGENT_LLM_MODEL_SETTINGS_STREAMING="False"
RESEARCH_AGENT_LLM_MODEL_SETTINGS_USE_RATE_LIMITER="True"
RESEARCH_AGENT_LLM_MAX_OUTPUT_TOKENS=50000
RESEARCH_AGENT_LLM_MAX_CONTEXT_LENGTH=100000
RESEARCH_AGENT_AUTO_START=false
RESEARCH_AGENT_DEFAULT_QUERIES=true

# ----------------------------------------------------------------------------------
# --- 11. Scrape Filter LLM Configuration ---
# (Controls: src.thoth.utilities.config.ScrapeFilterLLMConfig, env_prefix='SCRAPE_FILTER_LLM_')
# LLM for evaluating scraped article metadata before PDF download.
# ----------------------------------------------------------------------------------
SCRAPE_FILTER_LLM_MODEL="google/gemini-2.5-flash-preview-05-20"
SCRAPE_FILTER_LLM_MODEL_SETTINGS_TEMPERATURE="0.9"
SCRAPE_FILTER_LLM_MODEL_SETTINGS_MAX_TOKENS="10000"
SCRAPE_FILTER_LLM_MODEL_SETTINGS_TOP_P="1.0"
SCRAPE_FILTER_LLM_MODEL_SETTINGS_FREQUENCY_PENALTY="0.0"
SCRAPE_FILTER_LLM_MODEL_SETTINGS_PRESENCE_PENALTY="0.0"
SCRAPE_FILTER_LLM_MODEL_SETTINGS_STREAMING="False"
SCRAPE_FILTER_LLM_MODEL_SETTINGS_USE_RATE_LIMITER="True"
SCRAPE_FILTER_LLM_MAX_OUTPUT_TOKENS="10000"
SCRAPE_FILTER_LLM_MAX_CONTEXT_LENGTH="50000"

# ----------------------------------------------------------------------------------
# --- 12. Discovery System Configuration ---
# (Controls: src.thoth.utilities.config.DiscoveryConfig, env_prefix='DISCOVERY_')
# ----------------------------------------------------------------------------------
DISCOVERY_AUTO_START_SCHEDULER="False"
DISCOVERY_DEFAULT_MAX_ARTICLES="50"
DISCOVERY_DEFAULT_INTERVAL_MINUTES="60"
DISCOVERY_RATE_LIMIT_DELAY="1.0"
DISCOVERY_CHROME_EXTENSION_ENABLED="True"
DISCOVERY_CHROME_EXTENSION_PORT="8765"

# ----------------------------------------------------------------------------------
# --- 13. Research Agent Configuration ---
# (Controls: src.thoth.utilities.config.ResearchAgentConfig, env_prefix='RESEARCH_AGENT_')
# ----------------------------------------------------------------------------------
RESEARCH_AGENT_AUTO_START="False"
RESEARCH_AGENT_DEFAULT_QUERIES="True"

# ----------------------------------------------------------------------------------
# --- 14. Miscellaneous ---
# (Any additional settings from config.py not covered above)
# ----------------------------------------------------------------------------------

# RAG (Retrieval-Augmented Generation) Configuration
RAG_EMBEDDING_MODEL="openai/text-embedding-3-small"
RAG_EMBEDDING_BATCH_SIZE=100
RAG_VECTOR_DB_PATH="knowledge/vector_db"
RAG_COLLECTION_NAME="thoth_knowledge"
RAG_CHUNK_SIZE=1000
RAG_CHUNK_OVERLAP=200
RAG_QA_MODEL="openai/gpt-4o-mini"
RAG_QA_TEMPERATURE=0.2
RAG_QA_MAX_TOKENS=2000
RAG_RETRIEVAL_K=4

# ----------------------------------------------------------------------------------
# --- Docker-Specific Settings ---
# ----------------------------------------------------------------------------------

# Environment indicator
ENVIRONMENT="docker"

# Disable interactive features in Docker
PYTHONUNBUFFERED=1

# Development mode (set to true for development containers)
DEVELOPMENT=false

# ----------------------------------------------------------------------------------
# --- Security Settings ---
# ----------------------------------------------------------------------------------

# API key encryption (leave empty for development)
ENCRYPTION_KEY=

# Session settings
SESSION_TIMEOUT=3600

# Rate limiting for API endpoints
API_RATE_LIMIT=100
