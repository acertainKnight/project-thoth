# Thoth Configuration Example
# Copy this file to .env and fill in your actual values.
# Sections are ordered logically for easier management.

# ----------------------------------------------------------------------------------
# --- 1. API Keys ---
# (Controls: src.thoth.utilities.config.APIKeys, env_prefix='API_')
# ----------------------------------------------------------------------------------
API_MISTRAL_KEY="your_mistral_api_key_here"
API_OPENROUTER_KEY="your_openrouter_api_key_here"
API_OPENCITATIONS_KEY="your_opencitations_api_key_here"
# Optional: For Semantic Scholar API
API_SEMANTICSCHOLAR_API_KEY=""
# Legacy Google Search API (Optional)
# API_GOOGLE_API_KEY=""
# API_GOOGLE_SEARCH_ENGINE_ID=""

# ----------------------------------------------------------------------------------
# --- 2. Default Model Settings ---
# (Controls: src.thoth.utilities.config.ModelConfig, env_prefix='MODEL_')
# These are global defaults for any LLM model settings.
# They can be overridden by specific settings in LLMConfig and CitationLLMConfig.
# ----------------------------------------------------------------------------------
MODEL_TEMPERATURE="0.9"
# Default max tokens generated by an LLM call
MODEL_MAX_TOKENS="500000"
MODEL_TOP_P="1.0"
MODEL_FREQUENCY_PENALTY="0.0"
MODEL_PRESENCE_PENALTY="0.0"
MODEL_STREAMING="False"
MODEL_USE_RATE_LIMITER="True"

# ----------------------------------------------------------------------------------
# --- 3. General LLM Configuration ---
# (Controls: src.thoth.utilities.config.LLMConfig, env_prefix='LLM_')
# Configuration for the primary LLM used for content analysis, etc.
# ----------------------------------------------------------------------------------
# Specify the main LLM model identifier
LLM_MODEL="mistralai/Mixtral-8x7B-Instruct-v0.1"

# Specific model settings for the General LLM (overrides Default Model Settings)
# To set these, use LLM_MODEL_SETTINGS_<setting_name>
# Example: LLM_MODEL_SETTINGS_TEMPERATURE="0.7"
# Example: LLM_MODEL_SETTINGS_MAX_TOKENS="4000" # Max tokens generated by this LLM

# Processing parameters for the General LLM
# Strategy hint: 'auto', 'direct', 'refine', 'map_reduce'
LLM_DOC_PROCESSING="auto"
# Max *input document* tokens for 'direct' processing strategy
LLM_MAX_TOKENS="500000"
# Model's declared context window size
LLM_MAX_CONTEXT_LENGTH="8000"
# Chunk size for splitting long documents
LLM_CHUNK_SIZE="4000"
# Overlap between chunks
LLM_CHUNK_OVERLAP="200"
# Multiplier of max_context_length to choose 'refine' strategy
LLM_REFINE_THRESHOLD_MULTIPLIER="1.2"
# Multiplier of max_context_length to choose 'map_reduce' strategy
LLM_MAP_REDUCE_THRESHOLD_MULTIPLIER="3.0"

# ----------------------------------------------------------------------------------
# --- 4. Citation LLM Configuration ---
# (Controls: src.thoth.utilities.config.CitationLLMConfig, env_prefix='CITATION_LLM_')
# Configuration for the LLM used specifically for citation-related tasks.
# ----------------------------------------------------------------------------------
# Specify LLM for citation processing
CITATION_LLM_MODEL="openai/gpt-3.5-turbo"

# Specific model settings for the Citation LLM (overrides Default Model Settings)
# To set these, use CITATION_LLM_MODEL_SETTINGS_<setting_name>
# Example: CITATION_LLM_MODEL_SETTINGS_TEMPERATURE="0.5"
# Example: CITATION_LLM_MODEL_SETTINGS_MAX_TOKENS="500" # Max tokens generated by this LLM

# LLM parameters specific to citation tasks
# Max tokens *generated by* the citation LLM per call
CITATION_LLM_MAX_TOKENS="10000"
# Context length for the citation LLM
CITATION_LLM_MAX_CONTEXT_LENGTH="4000"

# ----------------------------------------------------------------------------------
# --- 5. Citation Processing Configuration ---
# (Controls: src.thoth.utilities.config.CitationConfig, env_prefix='CITATION_')
# Non-LLM settings for citation handling.
# ----------------------------------------------------------------------------------
# 'uri', 'wikilink', etc.
CITATION_LINK_FORMAT="uri"
# e.g., 'IEEE', 'APA'
CITATION_STYLE="IEEE"
# Use OpenCitations API for enrichment
CITATION_USE_OPENCITATIONS="True"
# Use Scholarly (Google Scholar) for enrichment
CITATION_USE_SCHOLARLY="True"
# Use Semantic Scholar API for enrichment
CITATION_USE_SEMANTICSCHOLAR="False"
# Use ArXiv API for enrichment
CITATION_USE_ARXIV="False"
# Batch size for LLM processing of citation strings (if applicable)
CITATION_CITATION_BATCH_SIZE="5"

# ----------------------------------------------------------------------------------
# --- 6. Endpoint Configuration ---
# (Controls: src.thoth.utilities.config.EndpointConfig, env_prefix='ENDPOINT_')
# Settings for the API server endpoint.
# ----------------------------------------------------------------------------------
ENDPOINT_HOST="0.0.0.0"
ENDPOINT_PORT="8000"
ENDPOINT_BASE_URL="http://localhost:8000"
# Whether to auto-start endpoint with the monitor
ENDPOINT_AUTO_START="False"

# ----------------------------------------------------------------------------------
# --- 7. Monitor Configuration ---
# (Controls: src.thoth.utilities.config.MonitorConfig, env_prefix='MONITOR_')
# Settings for the file monitoring service.
# ----------------------------------------------------------------------------------
MONITOR_AUTO_START="False"
# Interval in seconds to check for new files
MONITOR_WATCH_INTERVAL="10"
# Number of files to process in bulk
MONITOR_BULK_PROCESS_SIZE="10"

# ----------------------------------------------------------------------------------
# --- 8. Logging Configuration ---
# (Controls: src.thoth.utilities.config.LoggingConfig, env_prefix='LOG_')
# ----------------------------------------------------------------------------------
# Console logging level: 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'
LOG_LEVEL="INFO"
LOG_LOGFORMAT="{time} | {level} | {file}:{line} | {function} | {message}"
LOG_DATEFORMAT="YYYY-MM-DD HH:mm:ss"
# Path relative to workspace_dir
LOG_FILENAME="logs/thoth.log"
# 'a' for append, 'w' for overwrite
LOG_FILEMODE="a"
# File logging level
LOG_FILE_LEVEL="INFO"

# ----------------------------------------------------------------------------------
# --- 9. Thoth Base Paths (Defaults from ThothConfig) ---
# These are typically not set in .env unless you need to override the defaults
# defined in src.thoth.utilities.config.ThothConfig.
# They are loaded directly by ThothConfig without a prefix.
# ----------------------------------------------------------------------------------
# WORKSPACE_DIR="."
# PDF_DIR="data/pdf"
# MARKDOWN_DIR="data/markdown"
# NOTES_DIR="data/notes"
# PROMPTS_DIR="data/prompts"
# TEMPLATES_DIR="data/templates"
# OUTPUT_DIR="data/output"
# KNOWLEDGE_BASE_DIR="data/knowledge"
# GRAPH_STORAGE_PATH="data/graph/citations.graphml"
