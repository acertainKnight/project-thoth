"""
Note Regeneration Service

Regenerates Obsidian notes from stored database analysis data without re-running LLM inference.
This allows recovering notes or changing note templates without expensive re-processing.
"""  # noqa: W505

import asyncio  # noqa: I001
from pathlib import Path
from typing import Any

import asyncpg
from loguru import logger
from pydantic import BaseModel  # noqa: F401

from thoth.analyze.llm_processor import AnalysisResponse
from thoth.analyze.citations.citations import Citation
from thoth.config import config


class NoteRegenerationService:
    """Service for regenerating notes from stored database analysis."""

    def __init__(self):
        """Initialize the note regeneration service."""
        self.db_url = config.secrets.database_url
        self.note_service = None  # Will be initialized when needed

    async def get_paper_analysis(
        self, paper_id: str | None = None, title: str | None = None
    ) -> dict[str, Any] | None:
        """
        Retrieve paper analysis data from database.

        Args:
            paper_id: UUID of the paper
            title: Title of the paper (alternative to paper_id)

        Returns:
            Dictionary containing paper metadata and analysis data
        """
        if not paper_id and not title:
            raise ValueError('Either paper_id or title must be provided')

        conn = await asyncpg.connect(self.db_url)
        try:
            if paper_id:
                query = """
                    SELECT id, title, doi, arxiv_id, authors, abstract, year, venue,
                           pdf_path, note_path, markdown_content, analysis_data, llm_model
                    FROM papers
                    WHERE id = $1
                """
                row = await conn.fetchrow(query, paper_id)
            else:
                query = """
                    SELECT id, title, doi, arxiv_id, authors, abstract, year, venue,
                           pdf_path, note_path, markdown_content, analysis_data, llm_model
                    FROM papers
                    WHERE title = $1
                    LIMIT 1
                """
                row = await conn.fetchrow(query, title)

            if not row:
                logger.warning(f'Paper not found: paper_id={paper_id}, title={title}')
                return None

            if not row['analysis_data']:
                logger.warning(f'Paper has no analysis data: {row["title"]}')
                return None

            return dict(row)

        finally:
            await conn.close()

    async def get_paper_citations(self, paper_id: str) -> list[dict[str, Any]]:
        """
        Retrieve citations for a paper from database.

        Args:
            paper_id: UUID of the paper

        Returns:
            List of citation dictionaries
        """
        conn = await asyncpg.connect(self.db_url)
        try:
            query = """
                SELECT c.*, p.title as cited_title, p.authors as cited_authors,
                       p.year as cited_year, p.venue as cited_venue
                FROM citations c
                LEFT JOIN papers p ON c.cited_paper_id = p.id
                WHERE c.citing_paper_id = $1
                ORDER BY c.citation_order NULLS LAST
            """
            rows = await conn.fetch(query, paper_id)
            return [dict(row) for row in rows]

        finally:
            await conn.close()

    def _convert_analysis_to_model(
        self, analysis_data: dict[str, Any]
    ) -> AnalysisResponse:
        """
        Convert stored analysis data dict to AnalysisResponse model.

        Args:
            analysis_data: Raw analysis data from database

        Returns:
            AnalysisResponse model instance
        """
        # The analysis_data is already in the correct format (AnalysisResponse.model_dump())  # noqa: W505
        return AnalysisResponse(**analysis_data)

    def _convert_citations_to_models(
        self, citations_data: list[dict[str, Any]]
    ) -> list[Citation]:
        """
        Convert stored citation data to Citation models.

        Args:
            citations_data: List of citation dicts from database

        Returns:
            List of Citation model instances
        """
        citations = []
        for cit in citations_data:
            # Build Citation object from database fields
            citation = Citation(
                title=cit.get('extracted_title') or cit.get('cited_title', ''),
                authors=cit.get('extracted_authors') or cit.get('cited_authors', []),
                year=cit.get('extracted_year') or cit.get('cited_year'),
                venue=cit.get('extracted_venue') or cit.get('cited_venue'),
                doi=None,  # Not stored in citations table currently
                arxiv_id=None,  # Not stored in citations table currently
                obsidian_uri=None,  # Will be generated by note service
            )
            citations.append(citation)
        return citations

    async def regenerate_note(
        self, paper_id: str | None = None, title: str | None = None, force: bool = False
    ) -> tuple[str, str, str] | None:
        """
        Regenerate note for a paper from stored database data.

        Args:
            paper_id: UUID of the paper
            title: Title of the paper (alternative to paper_id)
            force: If True, regenerate even if note already exists

        Returns:
            Tuple of (note_path, pdf_path, markdown_path) or None if failed
        """
        # Get paper data from database
        paper_data = await self.get_paper_analysis(paper_id=paper_id, title=title)
        if not paper_data:
            return None

        paper_id = paper_data['id']

        # Check if note already exists
        note_path = paper_data.get('note_path')
        if note_path and Path(note_path).exists() and not force:
            logger.info(
                f'Note already exists: {note_path}. Use force=True to regenerate.'
            )
            return (
                note_path,
                paper_data.get('pdf_path', ''),
                paper_data.get('markdown_content', ''),
            )

        # Get citations
        citations_data = await self.get_paper_citations(paper_id)

        # Convert to model instances
        analysis = self._convert_analysis_to_model(paper_data['analysis_data'])
        citations = self._convert_citations_to_models(citations_data)

        # Ensure we have pdf_path and markdown_path
        up = self._get_user_paths()
        _vault_root = up.vault_root if up else Path(config.vault_root)
        _md_dir = up.markdown_dir if up else self.config.markdown_dir
        pdf_path = Path(paper_data.get('pdf_path', ''))
        if not pdf_path.is_absolute():
            pdf_path = (
                _vault_root / 'thoth' / 'papers' / 'pdfs' / pdf_path.name
                if pdf_path.name
                else None
            )

        markdown_path = _md_dir / f'{paper_data["title"]}.md'
        if paper_data.get('markdown_content'):
            markdown_path.parent.mkdir(parents=True, exist_ok=True)
            markdown_path.write_text(paper_data['markdown_content'], encoding='utf-8')

        # Initialize note service if needed
        if not self.note_service:
            from thoth.services.note_service import NoteService

            self.note_service = NoteService()

        # Generate note using note service
        logger.info(f'Regenerating note for: {paper_data["title"]}')
        try:
            note_path, new_pdf_path, new_markdown_path = self.note_service.create_note(
                pdf_path=pdf_path,
                markdown_path=markdown_path,
                analysis=analysis,
                citations=citations,
            )

            # Update database with new paths
            # 'papers' is a VIEW; update processed_papers table
            conn = await asyncpg.connect(self.db_url)
            try:
                await conn.execute(
                    """
                    INSERT INTO processed_papers (paper_id, note_path, pdf_path, created_at, updated_at)
                    VALUES ($1, $2, $3, NOW(), NOW())
                    ON CONFLICT (paper_id) DO UPDATE SET
                        note_path = EXCLUDED.note_path,
                        pdf_path = EXCLUDED.pdf_path,
                        updated_at = NOW()
                    """,
                    paper_id,
                    str(note_path),
                    str(new_pdf_path),
                )
            finally:
                await conn.close()

            logger.success(f'Successfully regenerated note: {note_path}')
            return (str(note_path), str(new_pdf_path), str(new_markdown_path))

        except Exception as e:
            logger.error(f'Failed to regenerate note: {e}')
            raise

    async def regenerate_all_notes(
        self, limit: int | None = None, force: bool = False
    ) -> dict[str, int]:
        """
        Regenerate notes for all papers with analysis data.

        Args:
            limit: Maximum number of papers to process (None for all)
            force: If True, regenerate even if notes already exist

        Returns:
            Dictionary with counts of success, skipped, and failed
        """
        conn = await asyncpg.connect(self.db_url)
        try:
            query = """
                SELECT id, title
                FROM papers
                WHERE analysis_data IS NOT NULL
                ORDER BY created_at DESC
            """
            if limit:
                query += f' LIMIT {limit}'

            rows = await conn.fetch(query)

            logger.info(f'Found {len(rows)} papers with analysis data')

            success = 0
            skipped = 0
            failed = 0

            for row in rows:
                try:
                    result = await self.regenerate_note(paper_id=row['id'], force=force)
                    if result:
                        success += 1
                        logger.info(
                            f'[{success}/{len(rows)}] Regenerated: {row["title"]}'
                        )
                    else:
                        skipped += 1
                        logger.info(
                            f'[{success + skipped}/{len(rows)}] Skipped: {row["title"]}'
                        )
                except Exception as e:
                    failed += 1
                    logger.error(
                        f'[{success + skipped + failed}/{len(rows)}] Failed: {row["title"]} - {e}'
                    )

            logger.info(
                f'Regeneration complete: {success} success, {skipped} skipped, {failed} failed'
            )
            return {
                'success': success,
                'skipped': skipped,
                'failed': failed,
                'total': len(rows),
            }

        finally:
            await conn.close()


# Convenience functions for CLI usage
async def regenerate_note_by_title(
    title: str, force: bool = False
) -> tuple[str, str, str] | None:
    """Regenerate note for a paper by title."""
    service = NoteRegenerationService()
    return await service.regenerate_note(title=title, force=force)


async def regenerate_all_notes(
    limit: int | None = None, force: bool = False
) -> dict[str, int]:
    """Regenerate notes for all papers with analysis data."""
    service = NoteRegenerationService()
    return await service.regenerate_all_notes(limit=limit, force=force)


if __name__ == '__main__':
    import sys

    if len(sys.argv) < 2:
        print(
            'Usage: python -m thoth.services.note_regeneration_service <command> [args]'
        )
        print('Commands:')
        print('  regenerate <title>  - Regenerate note for paper by title')
        print(
            '  regenerate-all [limit]  - Regenerate all notes (optionally limit count)'
        )
        sys.exit(1)

    command = sys.argv[1]

    if command == 'regenerate':
        if len(sys.argv) < 3:
            print('Error: Title required')
            sys.exit(1)
        title = ' '.join(sys.argv[2:])
        result = asyncio.run(regenerate_note_by_title(title, force=True))
        if result:
            print(f'Success! Note: {result[0]}')
        else:
            print('Failed to regenerate note')
            sys.exit(1)

    elif command == 'regenerate-all':
        limit = int(sys.argv[2]) if len(sys.argv) > 2 else None
        results = asyncio.run(regenerate_all_notes(limit=limit, force=False))
        print(f'Results: {results}')

    else:
        print(f'Unknown command: {command}')
        sys.exit(1)
