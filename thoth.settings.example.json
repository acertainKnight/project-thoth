{
  "$schema": "./thoth.settings.schema.json",
  "_comment": "Thoth settings - place this file in your Obsidian vault at .thoth/settings.json",
  "llm": {
    "default_model": "openai/gpt-4o-mini",
    "temperature": 0.7,
    "max_tokens": 4000,
    "top_p": 1.0,
    "frequency_penalty": 0.0,
    "presence_penalty": 0.0
  },
  "citation": {
    "link_format": "uri",
    "style": "IEEE",
    "use_opencitations": true,
    "use_scholarly": true,
    "use_semantic_scholar": false
  },
  "rag": {
    "embedding_model": "openai/text-embedding-3-small",
    "chunk_size": 1000,
    "chunk_overlap": 200,
    "retrieval_k": 4
  },
  "paths": {
    "workspace": ".thoth",
    "pdf": ".thoth/data/pdfs",
    "markdown": ".thoth/data/markdown",
    "notes": ".thoth/data/notes",
    "prompts": ".thoth/data/prompts",
    "templates": ".thoth/data/templates",
    "output": ".thoth/exports",
    "knowledge": ".thoth/data/knowledge",
    "queries": ".thoth/data/queries",
    "logs": ".thoth/logs",
    "cache": ".thoth/cache"
  },
  "features": {
    "enable_research_agent": true,
    "enable_citations": true,
    "enable_discovery": true,
    "enable_rag": true,
    "enable_mcp_server": true
  },
  "log_level": "INFO"
}
