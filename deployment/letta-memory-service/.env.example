# ==============================================================================
# Letta Memory Service Environment Configuration
# ==============================================================================

# Database Configuration
LETTA_DB_PASSWORD=secure_memory_password_change_in_production
LETTA_DB_PORT=5433

# Redis Configuration
LETTA_REDIS_PORT=6380

# Letta Server Configuration
LETTA_PORT=8283
LETTA_SERVER_PASSWORD=
LETTA_SECURE_MODE=false  # Set to true for production
LETTA_CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# API Keys (required)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_key_optional

# Performance Tuning
LETTA_POOL_SIZE=50
LETTA_PG_POOL_SIZE=20
LETTA_PG_MAX_OVERFLOW=40
LETTA_CACHE_TTL=3600

# Logging
LETTA_LOG_LEVEL=INFO

# Optional: Reverse Proxy
LETTA_PROXY_PORT=8284

# Optional: Monitoring
PROMETHEUS_PORT=9090

# ==============================================================================
# Production Scaling Options
# ==============================================================================

# For high availability, you can scale components:
# - Multiple Letta instances behind load balancer
# - PostgreSQL primary/replica setup
# - Redis cluster for distributed caching
# - Separate vector store (Pinecone, Weaviate, etc.)

# Example production scaling:
# LETTA_REPLICAS=3
# POSTGRES_REPLICAS=2
# REDIS_CLUSTER_ENABLED=true
# VECTOR_STORE_TYPE=pinecone
# VECTOR_STORE_API_KEY=your_pinecone_key
